{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc451b79-5b16-439f-ae8a-4caca470ceab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, plot_precision_recall_curve, plot_roc_curve, recall_score, f1_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder\n",
    "from pandas_profiling import ProfileReport\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ed58cf-f162-485e-8fef-82be6b7acfd6",
   "metadata": {},
   "source": [
    "# Predicting heart failures: Supporting clinical decisions for the health and wellness of cardiovascular disease patients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cd4d08-ca21-4894-ae1c-3e7ac20b12d2",
   "metadata": {},
   "source": [
    "## Problem Overview\n",
    "\n",
    "[Heart failure](https://www.uchealth.com/en/conditions/heart-failure) is a progressive condition where the heart muscle gradually loses its ability to pump blood throughout the body. As the current leading cause of death worldwide, cardiovascular diseases (CVDs) account for over [$20\n",
    "billion direct and indirect costs](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2722492/#:~:text=CVD%20was%20also%20the%20most,and%20physician%20care%20for%2012%25.) for the Canadian healthcare system each year. With no known cure for CVD, patients often require complex treatments to manage the condition.\n",
    "\n",
    "However, CVDs are preventable in their early stages. Individuals can interfere with its progression by controlling certain risk factors once it is identified by their healthcare provider. By analyzing clinical data, I hope to better identify individuals who are at risk of heart failure using machine learning. Its predictions could lend support to healthcare providers by reinforcing early detection and intervention strategies.\n",
    "\n",
    "The goal of this analysis is to predict whether a patient will die from heart failure or survive, based on demographics such as their age or sex and various lab test results. My model outputs predictions for the `DEATH_EVENT` column: 0 means that the patient survived and 1 means that they died. The data is sourced from the 'Heart Failure Prediction' dataset on [Kaggle](https://www.kaggle.com/andrewmvd/heart-failure-clinical-data)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180d891c-222b-421f-897c-961c2c4ece37",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "First, I split the data into two sets with 75% assigned for training and 25% for testing my model. I separated each set into two groups: X = columns containing values I will use to predict and y = column I am trying to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c6fc7d-7f4e-45cc-af0e-5684ddf05b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_df = pd.read_csv('../data/heart_failure_clinical_records_dataset.csv')\n",
    "hf_train, hf_test = train_test_split(hf_df, random_state=123)\n",
    "\n",
    "X_train = hf_train.drop(columns=['DEATH_EVENT'])\n",
    "y_train = hf_train['DEATH_EVENT']\n",
    "\n",
    "X_test = hf_test.drop(columns=['DEATH_EVENT'])\n",
    "y_test = hf_test['DEATH_EVENT']\n",
    "\n",
    "hf_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a689a388-a998-4f8e-a1c4-9aa5cf2a7eb8",
   "metadata": {},
   "source": [
    "The dataset consists of 13 feature columns with 6 containing only 0 or 1 as a value. 1 represents the presence of a condition and 0 represents the absence. For the `sex` column, 0 is female and 1 is male. For the `smoking` column, 0 indicates a non-smoker and 1 is for smokers. `time` is the patient's follow-up period in days.\n",
    "\n",
    "Furthermore, there is a large range of values for the `creatinine_phosphokinase`, `platelets` and `serum_creatinine` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3e4571-1d58-4af7-83ef-185ee13fa3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_train.describe().loc[['min', 'max'], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c35f83a-003a-4813-bc0a-2b6b788233ee",
   "metadata": {},
   "source": [
    "I decided not to drop any patients from the dataset, even though the extreme values could be considered 'outliers'. This was because:\n",
    "1) Amount of accessible data is very limited (< 300 samples); should ideally keep as much as possible\n",
    "2) Clinical values have been shown to fluctuate depending on the individual based on their [race and sex](https://www.portea.com/labs/diagnostic-tests/creatine-phosphokinase-cpk-ck-mb-bb-mm-83/#:~:text=CPK%20blood%20tests%20the%20different,26%20%E2%80%93%20192%20U%2FL)\n",
    "3) **Values that are inflated or deflated above normal range could be indicative of clinical disease and are not uncommon to observe in medical practice**\n",
    "\n",
    "I have highlighted this principle using the figure below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89a55a4-e983-40da-89ba-4df34ac7fe72",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax1, ax2), (ax3, ax4), (ax5, ax6)) = plt.subplots(3, 2, figsize=(15, 15), constrained_layout=True)\n",
    "axs = [ax1, ax2, ax3, ax4, ax5, ax6]\n",
    "data = [hf_train.age, hf_train.creatinine_phosphokinase, hf_train.ejection_fraction,\n",
    "        hf_train.platelets, hf_train.serum_creatinine, hf_train.serum_sodium]\n",
    "titles = ['Age', 'Creatinine Phosphokinase', 'Ejection Fraction', 'Platelets',\n",
    "          'Serum Creatinine', 'Serum Sodium']\n",
    "xlabels = ['Years', 'CPK Level (mcg/L)', '% of Blood Leaving Heart per Contraction',\n",
    "           'Platelet Level (kiloplatelets/mL)', 'Serum Creatinine Level (mg/dL)',\n",
    "           'Serum Sodium Level (mEg/L)']\n",
    "\n",
    "for n in range(len(axs)):\n",
    "    axs[n].hist(data[n].loc[hf_train['DEATH_EVENT'] == 0], bins=30, alpha=0.5, label='Survived')\n",
    "    axs[n].hist(data[n].loc[hf_train['DEATH_EVENT'] == 1], bins=30, alpha=0.5, label='Deceased')\n",
    "    axs[n].set_title('Histogram of ' + titles[n])\n",
    "    axs[n].set_xlabel(xlabels[n])\n",
    "    axs[n].set_ylabel('Frequency')\n",
    "    axs[n].legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354406b3-6fd4-4827-b0ce-1bd148f35bc3",
   "metadata": {},
   "source": [
    "Generally, there are equal proportions of patients who survive or die from heart disease outside of the average range for each feature. Since every person in the dataset was assessed in-hospital and had lab work conducted, I assumed that these values would be observed in the typical population that is screened for CVD and thus, my model should be able to address them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0196d561-268b-4fbc-8ee1-ce9012bbc12f",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "I sorted columns into two groups: binary (those with only 0 or 1) and numeric. Missing values in binary columns would be replaced by the most frequent value of the column. Missing values in numeric columns would be replaced by the median. These were also scaled to be roughly proportional to each other. This prevents large values from having a greater impact on the model's performance just from being bigger than others, rather than because of a relevant connection to `DEATH_EVENT`.\n",
    "\n",
    "The `time` column was also dropped. If we want to predict outcomes for patients who have just been assessed by their healthcare provider, we would not know the total days for their follow-up period during recovery and the model would be missing information that is necessary for predictions if included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da154e4-9450-40c0-bd5f-703944b70627",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['age', 'creatinine_phosphokinase', 'ejection_fraction', 'platelets',\n",
    "                    'serum_creatinine', 'serum_sodium']\n",
    "binary_features = ['anaemia', 'diabetes', 'high_blood_pressure', 'sex', 'smoking']\n",
    "target_column = 'DEATH_EVENT'\n",
    "drop_features = 'time' # this will be dropped automatically in the process\n",
    "\n",
    "binary_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent'))\n",
    "])\n",
    "\n",
    "numeric_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('binary', binary_transformer, binary_features),\n",
    "    ('numeric', numeric_transformer, numeric_features)\n",
    "])\n",
    "\n",
    "preprocessor.fit(hf_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191c3706-6f61-4d6c-9988-141096accb9d",
   "metadata": {},
   "source": [
    "## LogisticRegression: With vs Without Class Balancing\n",
    "I trained a LogisiticRegression (LR) model to generate the predictions. From the LR coefficients, we can identify features that are most significant in predicting heart failure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af36af81-2e09-4c68-aab0-cc3f25b93a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipe = make_pipeline(preprocessor, LogisticRegression(max_iter=1000))\n",
    "lr_pipe.fit(X_train, y_train);\n",
    "weight_df = pd.DataFrame(data=lr_pipe[1].coef_.ravel(), index=(numeric_features+binary_features), columns=['Coefficient'])\n",
    "weight_df.sort_values(by='Coefficient', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889f36eb-52db-4902-b173-61b8e3a93015",
   "metadata": {},
   "source": [
    "A higher level of serum sodium in the blood seems to increase the predicted probability that the patient will die of heart failure. In contrast, the model interpretted that someone will have a lower predicted probability of dying if they have diabetes (i.e. they are more likely to survive; more on this later).\n",
    "\n",
    "It is important to note that only 65 of the patients in the training set died while 159 survived. For this problem, I want to intervene especially for people who are at risk, even if it means offering more treatments to patients who may actually survive. Thus, it is better to have a **high recall** or increased true positive (TP) rate. Because there are comparatively fewer cases in the data, the model does not do a great job at predicting deaths and instead places more value on correctly identifying the patients who survived. To counteract this, I weighed false negatives as being 3 times more problematic than false positives because there is roughly 2.5 times more instances of class 0 in the target column compared to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0d0390-a4e8-4465-bab4-2a63cb474a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipe_balanced = make_pipeline(preprocessor, LogisticRegression(max_iter=1000, class_weight={1:3}))\n",
    "lr_pipe_balanced.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f142be-2d7e-47c6-b711-6e6accef3230",
   "metadata": {},
   "source": [
    "This increased the model's likelihood of predicting that a patient will die by making class 1 more important. We can observe this change by looking at the differences between each LR variations' confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df10df7d-eca8-47b6-bc34-4a47e864a976",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(15, 5), constrained_layout=True)\n",
    "plot_confusion_matrix(lr_pipe, X_train, y_train, display_labels=['Not Deceased', 'Deceased'], ax=ax1)\n",
    "ax1.set_title('LogisticRegression \\n (no balancing)')\n",
    "plot_confusion_matrix(lr_pipe_balanced, X_train, y_train, display_labels=['Not Deceased', 'Deceased'], ax=ax2)\n",
    "ax2.set_title('LogisticRegression \\n (with balancing)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b6eb33-5d95-4774-bbc2-020548dc34f1",
   "metadata": {},
   "source": [
    "The LR without balancing only caught 25/65 deceased cases, whereas the LR with balancing correctly identified 51. Comparatively, the unbalanced LR more accurately detected cases that survived (152/159) and the balanced LR incorrectly predicted 57 cases as deceased when the patient actually survives. The balance between the true and false positive (FP) rates is also easily visualized on an ROC curve for the LR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffa7188-ddfd-45c3-ad0c-54cc4f1b9cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_lr = confusion_matrix(y_train, lr_pipe.predict(X_train))\n",
    "cm_lrb = confusion_matrix(y_train, lr_pipe_balanced.predict(X_train))\n",
    "plot_roc_curve(lr_pipe, X_train, y_train);\n",
    "plt.plot(cm_lr[0,1]/(cm_lr[0].sum()), cm_lr[1,1]/(cm_lr[1].sum()), '*r', markersize=10, label='No Balancing');\n",
    "plt.plot(cm_lrb[0,1]/(cm_lrb[0].sum()), cm_lrb[1,1]/(cm_lrb[1].sum()), '*g', markersize=10, label='With Balancing');\n",
    "plt.title('LogisticRegression ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083047be-b36c-4851-802c-f8d42a409577",
   "metadata": {},
   "source": [
    "While the unbalanced LR keeps the FP rate relatively low (red star, <10%), it also ends up with a fairly low TP rate (~ 40%). The balanced LR increases both (~ 80% TP and <40% FP rates), which is preferred since we want a high TP rate without severely overestimating the number of deceased cases. Therefore, adjusting the class weights produces better results for this task.\n",
    "\n",
    "Attempting to further improve the model, I used RandomizedSearchCV to optimize the hyperparameter C used by LR. This assessed 10 different LR models with unique values of C to identify the one that produces the best results, which in this case is the highest average F1 score over 5 cross-validation folds. I chose to optimize F1 score as it captures both the precision (how many predicted deaths are actual deaths) and recall scores, and is generally perceived as a good evaluation metric when there is a class imbalance in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d88ef0-3f64-46c9-b450-3f24c38a5433",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_param_grid = {\n",
    "    \"logisticregression__C\" : 2.0**np.arange(-5,5)\n",
    "}\n",
    "lrbcv = RandomizedSearchCV(lr_pipe_balanced, lr_param_grid, scoring='f1_micro', n_jobs=-1)\n",
    "lrbcv.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e700789b-2826-4338-a12b-0f7cc4529779",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The best C value for the LogisticRegression model is {lrbcv.best_params_['logisticregression__C']}.\")\n",
    "print(f\"The F1 score produced by the best LogisticRegression model is {lrbcv.best_score_:.2f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e06552-9d0d-4bb0-9f2b-4c7e92b2444a",
   "metadata": {},
   "source": [
    "To summarize, the best and final LogisticRegression model for this problem has each class reweighted at 1 to 3 for 0 (survived) and 1 (died of heart failure) respectively, as well as a C value of 0.25. The average F1 validation score produced by this classifier is 0.62."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264037d9-db4f-4c8d-b094-47774b45b857",
   "metadata": {},
   "source": [
    "## Results - Model Comparison\n",
    "To determine whether the class weights had an effect on model performance, I compiled the F1 training, F1 validation and recall scores for LR with and without class balancing. We can also observe the effectiveness of the hyperparameter tuning after balancing by contrasting against the prior two models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656b2e2e-02d9-4857-b6cf-89741304b74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [lr_pipe, lr_pipe_balanced, lrbcv.best_estimator_]\n",
    "\n",
    "avg_train_score = []\n",
    "avg_val_score = []\n",
    "recall = []\n",
    "\n",
    "for m in models:\n",
    "    results = cross_validate(m, X_train, y_train, scoring='f1_micro', return_train_score=True)\n",
    "    avg_train_score.append(round(results['train_score'].mean(), 2))\n",
    "    avg_val_score.append(round(results['test_score'].mean(), 2))\n",
    "    recall.append(round(recall_score(y_train, m.predict(X_train)), 2))\n",
    "\n",
    "pd.DataFrame(list(zip(avg_train_score, avg_val_score, recall)),\n",
    "             index=['Without Balancing', 'With Balancing', 'After Tuning'],\n",
    "             columns=['Average Training Score', 'Average Validation Score', 'Recall Score'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d1d1f5-7b6b-4f14-b863-82e1b38f2b36",
   "metadata": {},
   "source": [
    "The average F1 train and validation scores both drop after the class balance is employed. However, 78% of heart failure deaths are caught by the class-balanced LR as indicated by the increase in recall score by 40%. This is an improvement as it is preferrable to overestimate possible deaths rather than miss over half.\n",
    "\n",
    "After tuning, the F1 training score goes down by 0.01 but it ends up producing a higher average F1 validation score compared to the balanced LR with the default C value. This is somewhat representative of how the model performs on unseen data and therefore, the hyperparameter tuning was successful. It is still producing lower train and validation scores than the unbalanced LR, but this model maintains the more ideal higher recall score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5726c683-821d-4654-9a64-9f6c6393117b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Recall test score = {recall_score(y_test, lrbcv.best_estimator_.predict(X_test)):.2f}\")\n",
    "print(f\"F1 test score = {f1_score(y_test, lrbcv.best_estimator_.predict(X_test), average='micro'):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdff54c-0840-469d-b63a-6ee5b51d074e",
   "metadata": {},
   "source": [
    "With a 0.72 F1 score and 84% recall, these results are surprisingly higher than the scores received using the training set. The confusion matrix below captures the LR's ability to identify 'Deceased' cases in the test set. These findings show that the model may adequately predict heart failure deaths for new patients! However, it should be noted that the test set only contains 75 samples and thus, these values may be overly optimistic of how good the model will operate in deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81507f2b-5a97-4e06-8be9-7e2388be250f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(lrbcv.best_estimator_, X_test, y_test, display_labels=['Not Deceased', 'Deceased'])\n",
    "plt.title('LogisticRegression - Test \\n (with balancing and tuning)');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4926a40c-0b4c-4eac-aabb-e3eb45b48ac7",
   "metadata": {},
   "source": [
    "## Short-comings and Future Plans\n",
    "The major downfall of this analysis is the size of the dataset. With only 224 samples to train on, the lack of data likely contributed to the model's unusual coefficients, implying that patients with diabetes are more likely to survive even though the literature states that it is [comorbid with CVD](https://spectrum.diabetesjournals.org/content/21/3/160). Risk factors such as high blood pressure and smoking should increase susceptibility to dying from heart failure, however the LR suggests that these features decrease a patient's likelihood of mortality. While the model does a reasonable job at predicting heart failure deaths here, I would expect it to perform more poorly on a different hospital population because of its misinterpretations of input features.\n",
    "\n",
    "As a result of the class imbalance, the model initially missed many death cases as it was biased towards the 0 class given its proportion in the dataset. I accounted for the low recall by manually making false negatives more problematic based on the 0:1 class ratio, but this lowered the precision to 47%; more than half of the patients who are predicted to die actually survive. This may be problematic if we consider the cost of wasted CVD treatments.\n",
    "\n",
    "By optimizing F1 score and favouring recall, we compromise the overall accuracy of the LR model. Since this problem cares most about detecting deaths, it is nearly impossible to identify a large number of patients at risk of heart failure and achieve a 80-90% accuracy with the data provided. The model will only be appropriately used in cases where death avoidance is a priority, and not if isolating survivors is required."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:573]",
   "language": "python",
   "name": "conda-env-573-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
